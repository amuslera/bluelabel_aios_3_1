"""
Monitoring and Observability Management for Jordan Kim

Handles monitoring setup, alerting configuration, and observability
implementation using Prometheus, Grafana, ELK stack, and cloud-native tools.
"""

import json
import yaml
import textwrap
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field


@dataclass
class MonitoringSpec:
    """Specification for monitoring requirements"""
    project_name: str
    environment: str
    
    # Metrics configuration
    metrics_retention_days: int = 15
    metrics_scrape_interval: str = "15s"
    enable_custom_metrics: bool = True
    
    # Logging configuration
    log_retention_days: int = 30
    log_level: str = "info"
    structured_logging: bool = True
    
    # Tracing configuration
    enable_tracing: bool = True
    trace_sampling_rate: float = 0.1
    
    # Alerting configuration
    alert_channels: List[str] = field(default_factory=lambda: ["email", "slack"])
    critical_alerts_phone: bool = False
    
    # Dashboards
    dashboard_templates: List[str] = field(default_factory=lambda: ["overview", "performance", "errors"])
    
    # SLOs
    availability_target: float = 99.9
    latency_p99_target_ms: int = 200
    error_rate_target: float = 0.1


@dataclass
class Alert:
    """Alert rule definition"""
    name: str
    expression: str
    duration: str
    severity: str
    summary: str
    description: str
    labels: Dict[str, str] = field(default_factory=dict)
    annotations: Dict[str, str] = field(default_factory=dict)


class MonitoringManager:
    """Manages monitoring and observability configuration"""
    
    def __init__(self):
        self.supported_backends = ['prometheus', 'datadog', 'cloudwatch', 'newrelic']
        self.supported_log_backends = ['elasticsearch', 'cloudwatch', 'splunk']
        
    def generate_monitoring_stack(self, spec: MonitoringSpec) -> Dict[str, str]:
        """Generate complete monitoring stack configuration"""
        configs = {}
        
        # Prometheus configuration
        configs['monitoring/prometheus/prometheus.yml'] = self._generate_prometheus_config(spec)
        configs['monitoring/prometheus/alerts.yml'] = self._generate_alert_rules(spec)
        
        # Grafana configuration
        configs['monitoring/grafana/dashboards/overview.json'] = self._generate_overview_dashboard(spec)
        configs['monitoring/grafana/dashboards/performance.json'] = self._generate_performance_dashboard(spec)
        configs['monitoring/grafana/dashboards/slo.json'] = self._generate_slo_dashboard(spec)
        configs['monitoring/grafana/provisioning/datasources/prometheus.yml'] = self._generate_datasource_config()
        
        # Alertmanager configuration
        configs['monitoring/alertmanager/alertmanager.yml'] = self._generate_alertmanager_config(spec)
        
        # Logging configuration
        configs['monitoring/logging/fluent-bit.conf'] = self._generate_fluentbit_config(spec)
        configs['monitoring/logging/elasticsearch/index-template.json'] = self._generate_es_index_template(spec)
        
        # Tracing configuration
        if spec.enable_tracing:
            configs['monitoring/tracing/jaeger-config.yml'] = self._generate_jaeger_config(spec)
            
        # Kubernetes manifests
        configs['monitoring/k8s/monitoring-namespace.yaml'] = self._generate_k8s_namespace()
        configs['monitoring/k8s/prometheus-deployment.yaml'] = self._generate_prometheus_deployment(spec)
        configs['monitoring/k8s/grafana-deployment.yaml'] = self._generate_grafana_deployment(spec)
        
        # Docker compose for local testing
        configs['monitoring/docker-compose.yml'] = self._generate_docker_compose(spec)
        
        # Documentation
        configs['monitoring/README.md'] = self._generate_monitoring_docs(spec)
        
        return configs
        
    def _generate_prometheus_config(self, spec: MonitoringSpec) -> str:
        """Generate Prometheus configuration"""
        return f"""# Prometheus Configuration
# Generated by Jordan Kim - DevOps Engineer

global:
  scrape_interval: {spec.metrics_scrape_interval}
  evaluation_interval: {spec.metrics_scrape_interval}
  external_labels:
    environment: '{spec.environment}'
    project: '{spec.project_name}'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

# Load rules files
rule_files:
  - "alerts.yml"
  - "recording_rules.yml"

# Scrape configurations
scrape_configs:
  # Prometheus self-monitoring
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node exporter
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  # Application metrics
  - job_name: '{spec.project_name}'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - {spec.project_name}-{spec.environment}
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\\d+)?;(\\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

  # Kubernetes metrics
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
      - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

  # Kubernetes nodes
  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)

  # Kubernetes pods
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\\d+)?;(\\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

# Remote storage for long-term retention
remote_write:
  - url: "http://thanos-receive:19291/api/v1/receive"
    write_relabel_configs:
      - source_labels: [__name__]
        regex: "prometheus_.*"
        action: drop
"""

    def _generate_alert_rules(self, spec: MonitoringSpec) -> str:
        """Generate Prometheus alert rules"""
        # Define standard alerts
        alerts = [
            Alert(
                name="HighErrorRate",
                expression=f'rate(http_requests_total{{status=~"5..",job="{spec.project_name}"}}[5m]) > {spec.error_rate_target/100}',
                duration="5m",
                severity="critical",
                summary="High error rate detected",
                description=f"Error rate is above {spec.error_rate_target}% for {spec.project_name}"
            ),
            Alert(
                name="HighLatency",
                expression=f'histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{{job="{spec.project_name}"}}[5m])) > {spec.latency_p99_target_ms/1000}',
                duration="5m",
                severity="warning",
                summary="High latency detected",
                description=f"99th percentile latency is above {spec.latency_p99_target_ms}ms"
            ),
            Alert(
                name="PodCrashLooping",
                expression='rate(kube_pod_container_status_restarts_total[5m]) > 0',
                duration="5m",
                severity="critical",
                summary="Pod is crash looping",
                description="Pod {{ $labels.pod }} has restarted {{ $value }} times in the last 5 minutes"
            ),
            Alert(
                name="HighMemoryUsage",
                expression='container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9',
                duration="5m",
                severity="warning",
                summary="High memory usage",
                description="Container {{ $labels.container }} memory usage is above 90%"
            ),
            Alert(
                name="DiskSpaceLow",
                expression='(node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1',
                duration="5m",
                severity="critical",
                summary="Low disk space",
                description="Less than 10% disk space available on {{ $labels.instance }}"
            ),
            Alert(
                name="ServiceDown",
                expression=f'up{{job="{spec.project_name}"}} == 0',
                duration="2m",
                severity="critical",
                summary="Service is down",
                description=f"{spec.project_name} service is down on {{{{ $labels.instance }}}}"
            )
        ]
        
        # Generate YAML
        rules_yaml = {
            'groups': [{
                'name': f'{spec.project_name}_alerts',
                'interval': '30s',
                'rules': []
            }]
        }
        
        for alert in alerts:
            rule = {
                'alert': alert.name,
                'expr': alert.expression,
                'for': alert.duration,
                'labels': {
                    'severity': alert.severity,
                    'project': spec.project_name,
                    'environment': spec.environment,
                    **alert.labels
                },
                'annotations': {
                    'summary': alert.summary,
                    'description': alert.description,
                    **alert.annotations
                }
            }
            rules_yaml['groups'][0]['rules'].append(rule)
            
        return yaml.dump(rules_yaml, default_flow_style=False)
        
    def _generate_overview_dashboard(self, spec: MonitoringSpec) -> str:
        """Generate Grafana overview dashboard"""
        dashboard = {
            "dashboard": {
                "title": f"{spec.project_name} Overview - {spec.environment}",
                "uid": f"{spec.project_name}-overview",
                "tags": ["overview", spec.project_name, spec.environment],
                "timezone": "browser",
                "panels": [
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
                        "id": 1,
                        "title": "Request Rate",
                        "type": "graph",
                        "targets": [{
                            "expr": f'sum(rate(http_requests_total{{job="{spec.project_name}"}}[5m])) by (status)',
                            "legendFormat": "{{status}}"
                        }]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
                        "id": 2,
                        "title": "Error Rate",
                        "type": "graph",
                        "targets": [{
                            "expr": f'sum(rate(http_requests_total{{job="{spec.project_name}",status=~"5.."}}[5m])) / sum(rate(http_requests_total{{job="{spec.project_name}"}}[5m])) * 100',
                            "legendFormat": "Error %"
                        }]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
                        "id": 3,
                        "title": "Response Time (p50, p95, p99)",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": f'histogram_quantile(0.5, sum(rate(http_request_duration_seconds_bucket{{job="{spec.project_name}"}}[5m])) by (le))',
                                "legendFormat": "p50"
                            },
                            {
                                "expr": f'histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{{job="{spec.project_name}"}}[5m])) by (le))',
                                "legendFormat": "p95"
                            },
                            {
                                "expr": f'histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{{job="{spec.project_name}"}}[5m])) by (le))',
                                "legendFormat": "p99"
                            }
                        ]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
                        "id": 4,
                        "title": "Active Connections",
                        "type": "graph",
                        "targets": [{
                            "expr": f'sum(http_connections_active{{job="{spec.project_name}"}}) by (instance)',
                            "legendFormat": "{{instance}}"
                        }]
                    }
                ],
                "refresh": "5s",
                "time": {"from": "now-1h", "to": "now"},
                "timepicker": {
                    "refresh_intervals": ["5s", "10s", "30s", "1m", "5m"]
                }
            }
        }
        
        return json.dumps(dashboard, indent=2)
        
    def _generate_performance_dashboard(self, spec: MonitoringSpec) -> str:
        """Generate Grafana performance dashboard"""
        dashboard = {
            "dashboard": {
                "title": f"{spec.project_name} Performance - {spec.environment}",
                "uid": f"{spec.project_name}-performance",
                "tags": ["performance", spec.project_name, spec.environment],
                "timezone": "browser",
                "panels": [
                    {
                        "gridPos": {"h": 8, "w": 8, "x": 0, "y": 0},
                        "id": 1,
                        "title": "CPU Usage",
                        "type": "graph",
                        "targets": [{
                            "expr": f'rate(container_cpu_usage_seconds_total{{pod=~"{spec.project_name}.*"}}[5m]) * 100',
                            "legendFormat": "{{pod}}"
                        }]
                    },
                    {
                        "gridPos": {"h": 8, "w": 8, "x": 8, "y": 0},
                        "id": 2,
                        "title": "Memory Usage",
                        "type": "graph",
                        "targets": [{
                            "expr": f'container_memory_usage_bytes{{pod=~"{spec.project_name}.*"}} / 1024 / 1024',
                            "legendFormat": "{{pod}}"
                        }]
                    },
                    {
                        "gridPos": {"h": 8, "w": 8, "x": 16, "y": 0},
                        "id": 3,
                        "title": "Network I/O",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": f'rate(container_network_receive_bytes_total{{pod=~"{spec.project_name}.*"}}[5m])',
                                "legendFormat": "RX {{pod}}"
                            },
                            {
                                "expr": f'rate(container_network_transmit_bytes_total{{pod=~"{spec.project_name}.*"}}[5m])',
                                "legendFormat": "TX {{pod}}"
                            }
                        ]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
                        "id": 4,
                        "title": "Goroutines",
                        "type": "graph",
                        "targets": [{
                            "expr": f'go_goroutines{{job="{spec.project_name}"}}',
                            "legendFormat": "{{instance}}"
                        }]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
                        "id": 5,
                        "title": "GC Duration",
                        "type": "graph",
                        "targets": [{
                            "expr": f'rate(go_gc_duration_seconds_sum{{job="{spec.project_name}"}}[5m])',
                            "legendFormat": "{{instance}}"
                        }]
                    }
                ],
                "refresh": "10s",
                "time": {"from": "now-1h", "to": "now"}
            }
        }
        
        return json.dumps(dashboard, indent=2)
        
    def _generate_slo_dashboard(self, spec: MonitoringSpec) -> str:
        """Generate SLO dashboard"""
        dashboard = {
            "dashboard": {
                "title": f"{spec.project_name} SLOs - {spec.environment}",
                "uid": f"{spec.project_name}-slo",
                "tags": ["slo", spec.project_name, spec.environment],
                "timezone": "browser",
                "panels": [
                    {
                        "gridPos": {"h": 8, "w": 8, "x": 0, "y": 0},
                        "id": 1,
                        "title": "Availability SLO",
                        "type": "stat",
                        "targets": [{
                            "expr": f'avg_over_time((1 - rate(http_requests_total{{job="{spec.project_name}",status=~"5.."}}[5m]) / rate(http_requests_total{{job="{spec.project_name}"}}[5m]))[30d:5m]) * 100',
                            "legendFormat": "Availability %"
                        }],
                        "fieldConfig": {
                            "defaults": {
                                "thresholds": {
                                    "mode": "absolute",
                                    "steps": [
                                        {"color": "red", "value": 0},
                                        {"color": "yellow", "value": 99},
                                        {"color": "green", "value": spec.availability_target}
                                    ]
                                },
                                "unit": "percent"
                            }
                        }
                    },
                    {
                        "gridPos": {"h": 8, "w": 8, "x": 8, "y": 0},
                        "id": 2,
                        "title": "Latency SLO (p99)",
                        "type": "stat",
                        "targets": [{
                            "expr": f'histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{{job="{spec.project_name}"}}[30d])) by (le)) * 1000',
                            "legendFormat": "p99 Latency"
                        }],
                        "fieldConfig": {
                            "defaults": {
                                "thresholds": {
                                    "mode": "absolute",
                                    "steps": [
                                        {"color": "green", "value": 0},
                                        {"color": "yellow", "value": spec.latency_p99_target_ms * 0.8},
                                        {"color": "red", "value": spec.latency_p99_target_ms}
                                    ]
                                },
                                "unit": "ms"
                            }
                        }
                    },
                    {
                        "gridPos": {"h": 8, "w": 8, "x": 16, "y": 0},
                        "id": 3,
                        "title": "Error Budget Remaining",
                        "type": "gauge",
                        "targets": [{
                            "expr": f'(1 - (1 - {spec.availability_target/100}) * (1 - avg_over_time((1 - rate(http_requests_total{{job="{spec.project_name}",status=~"5.."}}[5m]) / rate(http_requests_total{{job="{spec.project_name}"}}[5m]))[30d:5m]))) * 100',
                            "legendFormat": "Error Budget %"
                        }],
                        "fieldConfig": {
                            "defaults": {
                                "min": 0,
                                "max": 100,
                                "thresholds": {
                                    "mode": "absolute",
                                    "steps": [
                                        {"color": "red", "value": 0},
                                        {"color": "yellow", "value": 20},
                                        {"color": "green", "value": 50}
                                    ]
                                },
                                "unit": "percent"
                            }
                        }
                    }
                ],
                "refresh": "1m",
                "time": {"from": "now-30d", "to": "now"}
            }
        }
        
        return json.dumps(dashboard, indent=2)
        
    def _generate_datasource_config(self) -> str:
        """Generate Grafana datasource configuration"""
        return """apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
    jsonData:
      timeInterval: 15s
      
  - name: Elasticsearch
    type: elasticsearch
    access: proxy
    url: http://elasticsearch:9200
    database: "[logstash-]YYYY.MM.DD"
    jsonData:
      esVersion: "7.10.0"
      timeField: "@timestamp"
      
  - name: Jaeger
    type: jaeger
    access: proxy
    url: http://jaeger-query:16686
    editable: true
"""

    def _generate_alertmanager_config(self, spec: MonitoringSpec) -> str:
        """Generate Alertmanager configuration"""
        config = {
            'global': {
                'resolve_timeout': '5m'
            },
            'route': {
                'group_by': ['alertname', 'cluster', 'service'],
                'group_wait': '10s',
                'group_interval': '10s',
                'repeat_interval': '12h',
                'receiver': 'default',
                'routes': [
                    {
                        'match': {'severity': 'critical'},
                        'receiver': 'critical'
                    },
                    {
                        'match': {'severity': 'warning'},
                        'receiver': 'warning'
                    }
                ]
            },
            'receivers': []
        }
        
        # Default receiver
        config['receivers'].append({
            'name': 'default',
            'webhook_configs': [{
                'url': 'http://webhook-logger:8080/webhook',
                'send_resolved': True
            }]
        })
        
        # Critical receiver
        critical_receiver = {'name': 'critical'}
        if 'slack' in spec.alert_channels:
            critical_receiver['slack_configs'] = [{
                'api_url': '${SLACK_WEBHOOK_URL}',
                'channel': '#alerts-critical',
                'title': f'{spec.project_name} Critical Alert',
                'text': '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
            }]
        if spec.critical_alerts_phone:
            critical_receiver['pagerduty_configs'] = [{
                'service_key': '${PAGERDUTY_SERVICE_KEY}',
                'description': '{{ .GroupLabels.alertname }}'
            }]
        config['receivers'].append(critical_receiver)
        
        # Warning receiver
        warning_receiver = {'name': 'warning'}
        if 'email' in spec.alert_channels:
            warning_receiver['email_configs'] = [{
                'to': 'devops@example.com',
                'from': 'alertmanager@example.com',
                'smarthost': 'smtp.example.com:587',
                'auth_username': 'alertmanager@example.com',
                'auth_password': '${EMAIL_PASSWORD}',
                'headers': {'Subject': f'{spec.project_name} Warning Alert'}
            }]
        config['receivers'].append(warning_receiver)
        
        return yaml.dump(config, default_flow_style=False)
        
    def _generate_fluentbit_config(self, spec: MonitoringSpec) -> str:
        """Generate Fluent Bit configuration"""
        return f"""[SERVICE]
    Flush         5
    Daemon        Off
    Log_Level     {spec.log_level}
    Parsers_File  parsers.conf

[INPUT]
    Name              tail
    Tag               app.*
    Path              /var/log/containers/*_{spec.project_name}-{spec.environment}_*.log
    Parser            docker
    DB                /var/log/flb-app.db
    Mem_Buf_Limit     50MB
    Skip_Long_Lines   On
    Refresh_Interval  10

[FILTER]
    Name                kubernetes
    Match               app.*
    Kube_URL            https://kubernetes.default.svc.cluster.local:443
    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
    Merge_Log           On
    K8S-Logging.Parser  On
    K8S-Logging.Exclude On

[FILTER]
    Name    modify
    Match   app.*
    Add     environment {spec.environment}
    Add     project {spec.project_name}

[OUTPUT]
    Name            es
    Match           app.*
    Host            elasticsearch
    Port            9200
    Index           {spec.project_name}-{spec.environment}
    Type            _doc
    Retry_Limit     10
    
[OUTPUT]
    Name            stdout
    Match           app.*
    Format          json_lines
"""

    def _generate_es_index_template(self, spec: MonitoringSpec) -> str:
        """Generate Elasticsearch index template"""
        template = {
            "index_patterns": [f"{spec.project_name}-{spec.environment}-*"],
            "settings": {
                "number_of_shards": 3,
                "number_of_replicas": 1,
                "index.lifecycle.name": f"{spec.project_name}-ilm-policy",
                "index.lifecycle.rollover_alias": f"{spec.project_name}-{spec.environment}"
            },
            "mappings": {
                "properties": {
                    "@timestamp": {"type": "date"},
                    "level": {"type": "keyword"},
                    "logger": {"type": "keyword"},
                    "message": {"type": "text"},
                    "trace_id": {"type": "keyword"},
                    "span_id": {"type": "keyword"},
                    "service": {"type": "keyword"},
                    "environment": {"type": "keyword"},
                    "kubernetes": {
                        "properties": {
                            "namespace_name": {"type": "keyword"},
                            "pod_name": {"type": "keyword"},
                            "container_name": {"type": "keyword"},
                            "labels": {"type": "object"}
                        }
                    },
                    "error": {
                        "properties": {
                            "type": {"type": "keyword"},
                            "message": {"type": "text"},
                            "stack_trace": {"type": "text"}
                        }
                    }
                }
            },
            "aliases": {
                f"{spec.project_name}-{spec.environment}": {}
            }
        }
        
        return json.dumps(template, indent=2)
        
    def _generate_jaeger_config(self, spec: MonitoringSpec) -> str:
        """Generate Jaeger configuration"""
        return f"""# Jaeger Configuration
# Generated by Jordan Kim - DevOps Engineer

span-storage-type: elasticsearch

collector:
  zipkin:
    host-port: :9411
  grpc:
    host-port: :14250
  http:
    host-port: :14268
    
processor:
  jaeger-binary:
    server-host-port: :6832
  jaeger-compact:
    server-host-port: :6831
    
query:
  static-files: /go/bin/jaeger-ui
  base-path: /jaeger
  
es:
  server-urls: http://elasticsearch:9200
  index-prefix: {spec.project_name}-traces
  
sampling:
  strategies-file: /etc/jaeger/sampling.json
  
log-level: {spec.log_level}
"""

    def _generate_k8s_namespace(self) -> str:
        """Generate Kubernetes namespace for monitoring"""
        return """apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: monitoring-quota
  namespace: monitoring
spec:
  hard:
    requests.cpu: "10"
    requests.memory: "20Gi"
    persistentvolumeclaims: "10"
"""

    def _generate_prometheus_deployment(self, spec: MonitoringSpec) -> str:
        """Generate Prometheus Kubernetes deployment"""
        return f"""apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
{textwrap.indent(self._generate_prometheus_config(spec), '    ')}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus/'
          - '--storage.tsdb.retention.time={spec.metrics_retention_days}d'
          - '--web.console.libraries=/etc/prometheus/console_libraries'
          - '--web.console.templates=/etc/prometheus/consoles'
          - '--web.enable-lifecycle'
        ports:
        - containerPort: 9090
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        volumeMounts:
        - name: prometheus-config-volume
          mountPath: /etc/prometheus/
        - name: prometheus-storage-volume
          mountPath: /prometheus/
      volumes:
      - name: prometheus-config-volume
        configMap:
          name: prometheus-config
      - name: prometheus-storage-volume
        persistentVolumeClaim:
          claimName: prometheus-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
"""

    def _generate_grafana_deployment(self, spec: MonitoringSpec) -> str:
        """Generate Grafana Kubernetes deployment"""
        return f"""apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  prometheus.yml: |
{textwrap.indent(self._generate_datasource_config(), '    ')}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:10.0.0
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        - name: GF_INSTALL_PLUGINS
          value: grafana-clock-panel,grafana-simple-json-datasource
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: grafana-datasources
          mountPath: /etc/grafana/provisioning/datasources
        - name: grafana-dashboards
          mountPath: /etc/grafana/provisioning/dashboards
        - name: grafana-storage
          mountPath: /var/lib/grafana
      volumes:
      - name: grafana-datasources
        configMap:
          name: grafana-datasources
      - name: grafana-dashboards
        configMap:
          name: grafana-dashboards
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
"""

    def _generate_docker_compose(self, spec: MonitoringSpec) -> str:
        """Generate Docker Compose for local testing"""
        return f"""# Docker Compose for Monitoring Stack
# Generated by Jordan Kim - DevOps Engineer

version: '3.8'

services:
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:10.0.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager:/etc/alertmanager
      - alertmanager_data:/alertmanager
    networks:
      - monitoring

  node-exporter:
    image: prom/node-exporter:v1.6.0
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - monitoring

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.10
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - monitoring

  jaeger:
    image: jaegertracing/all-in-one:1.46
    container_name: jaeger
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:
  elasticsearch_data:

networks:
  monitoring:
    driver: bridge
"""

    def _generate_monitoring_docs(self, spec: MonitoringSpec) -> str:
        """Generate monitoring documentation"""
        return f"""# {spec.project_name} Monitoring Stack

## Overview
Complete monitoring and observability stack for {spec.project_name} in the {spec.environment} environment.

## Components

### Metrics - Prometheus
- **Retention**: {spec.metrics_retention_days} days
- **Scrape Interval**: {spec.metrics_scrape_interval}
- **Endpoints**: Application metrics, Kubernetes metrics, Node metrics

### Visualization - Grafana
- **Dashboards**: Overview, Performance, SLOs
- **Data Sources**: Prometheus, Elasticsearch, Jaeger
- **Access**: http://grafana.{spec.project_name}.com

### Logs - ELK Stack
- **Retention**: {spec.log_retention_days} days
- **Index Pattern**: {spec.project_name}-{spec.environment}-*
- **Access**: http://kibana.{spec.project_name}.com

### Tracing - Jaeger
- **Sampling Rate**: {spec.trace_sampling_rate * 100}%
- **Storage**: Elasticsearch
- **Access**: http://jaeger.{spec.project_name}.com

### Alerting - Alertmanager
- **Channels**: {', '.join(spec.alert_channels)}
- **Critical Alerts**: {'Phone enabled' if spec.critical_alerts_phone else 'Phone disabled'}

## SLOs

1. **Availability**: {spec.availability_target}%
2. **Latency (p99)**: < {spec.latency_p99_target_ms}ms
3. **Error Rate**: < {spec.error_rate_target}%

## Quick Start

### Local Development
```bash
cd monitoring
docker-compose up -d

# Access points:
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
# - Kibana: http://localhost:5601
# - Jaeger: http://localhost:16686
```

### Kubernetes Deployment
```bash
# Create namespace
kubectl apply -f k8s/monitoring-namespace.yaml

# Deploy Prometheus
kubectl apply -f k8s/prometheus-deployment.yaml

# Deploy Grafana
kubectl apply -f k8s/grafana-deployment.yaml

# Check status
kubectl get pods -n monitoring
```

## Alert Rules

### Critical Alerts
- Service Down (2 minutes)
- High Error Rate (> {spec.error_rate_target}% for 5 minutes)
- Pod Crash Looping
- Disk Space Low (< 10%)

### Warning Alerts
- High Latency (p99 > {spec.latency_p99_target_ms}ms)
- High Memory Usage (> 90%)
- Certificate Expiration (< 7 days)

## Dashboards

### Overview Dashboard
- Request rate by status code
- Error rate percentage
- Response time percentiles (p50, p95, p99)
- Active connections

### Performance Dashboard
- CPU usage by pod
- Memory usage by pod
- Network I/O
- GC statistics

### SLO Dashboard
- Current SLO status
- Error budget remaining
- Burn rate

## Troubleshooting

### No Metrics Appearing
1. Check Prometheus targets: http://prometheus:9090/targets
2. Verify pod annotations for scraping
3. Check network policies

### High Memory Usage
1. Reduce retention period
2. Increase Prometheus memory limits
3. Enable remote storage

### Missing Logs
1. Check Fluent Bit daemonset status
2. Verify Elasticsearch indices
3. Check log parsing configuration

## Maintenance

### Daily
- Check alert notifications
- Monitor error budgets
- Review any critical alerts

### Weekly
- Review dashboard usage
- Update alert thresholds if needed
- Check storage usage

### Monthly
- Review and update SLOs
- Audit access logs
- Update monitoring stack versions

## Support
For monitoring issues, contact the DevOps team.

---
Generated by Jordan Kim - DevOps Engineer
"""